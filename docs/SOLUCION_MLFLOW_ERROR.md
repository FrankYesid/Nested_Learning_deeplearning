# üîß Soluci√≥n: Error de Conexi√≥n con MLflow

## ‚ùå Error

```
ConnectionRefusedError: [WinError 10061] No se puede establecer una conexi√≥n ya que el equipo de destino deneg√≥ expresamente dicha conexi√≥n
MlflowException: API request to http://localhost:5000/api/2.0/mlflow/experiments/get-by-name failed
```

## üîç Causa

La API intenta conectarse a MLflow en `http://localhost:5000` pero el servidor MLflow **no est√° corriendo**.

## ‚úÖ Soluci√≥n

### Opci√≥n 1: Iniciar MLflow antes de la API (Recomendado)

**Terminal 1 - MLflow:**
```powershell
# Activar entorno virtual
.venv\Scripts\Activate.ps1

# Iniciar MLflow Tracking Server
mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri file:./mlruns --default-artifact-root file:./mlruns
```

**Terminal 2 - API:**
```powershell
# Activar entorno virtual
.venv\Scripts\Activate.ps1

# Iniciar API
python -m uvicorn src.infrastructure.api.main:app --host 0.0.0.0 --port 8000
```

### Opci√≥n 2: Usar Scripts de Ayuda

**Iniciar MLflow:**
```powershell
python run_mlflow.py
```

**Iniciar API:**
```powershell
python run_api.py
```

### Opci√≥n 3: Usar Docker Compose (Todo en uno)

```powershell
cd docker
docker-compose up --build
```

Esto inicia tanto MLflow como la API autom√°ticamente.

## üîÑ Cambios Realizados

He modificado el c√≥digo para que:

1. **Inicializaci√≥n Lazy**: MLflow solo se inicializa cuando se necesita, no al importar el m√≥dulo
2. **Manejo de Errores**: La API puede iniciar sin MLflow, mostrando advertencias
3. **Mensajes Claros**: Indicaciones sobre qu√© hacer si MLflow no est√° disponible

## üìã Verificaci√≥n

### 1. Verificar que MLflow est√© corriendo

Abre en tu navegador: http://localhost:5000

Deber√≠as ver la interfaz de MLflow.

### 2. Verificar que la API est√© funcionando

Abre en tu navegador: http://localhost:8000/health

Deber√≠as ver:
```json
{
  "status": "healthy",
  "model_loaded": false,
  "mlflow_available": true,
  "mlflow_uri": "http://localhost:5000"
}
```

### 3. Verificar endpoints

- **API Docs**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health
- **Model Info**: http://localhost:8000/model/info

## üöÄ Flujo de Trabajo Completo

### 1. Entrenar Modelo (Primera vez)

```powershell
# Iniciar MLflow
mlflow server --host 0.0.0.0 --port 5000

# En otra terminal, ejecutar notebook de entrenamiento
jupyter notebook notebooks/02_Nested_Learning_Training.ipynb
```

### 2. Iniciar Servicios para Producci√≥n

```powershell
# Terminal 1: MLflow
mlflow server --host 0.0.0.0 --port 5000

# Terminal 2: API
python -m uvicorn src.infrastructure.api.main:app --host 0.0.0.0 --port 8000
```

### 3. Usar la API

- **Frontend**: http://localhost:8000/frontend
- **API Docs**: http://localhost:8000/docs
- **Predicci√≥n**: POST http://localhost:8000/predict

## ‚ö†Ô∏è Notas Importantes

1. **MLflow debe estar corriendo** antes de entrenar modelos o usar la API con modelos
2. **El modelo debe estar registrado** en MLflow Model Registry antes de que la API pueda cargarlo
3. **El preprocessing service** debe estar guardado en `models/preprocessing_service.pkl`

## üêõ Troubleshooting

### Error: "MLflow no est√° disponible"

**Soluci√≥n**: Inicia MLflow primero:
```powershell
mlflow server --host 0.0.0.0 --port 5000
```

### Error: "Modelo no encontrado"

**Soluci√≥n**: Entrena y registra el modelo:
1. Ejecuta el notebook `02_Nested_Learning_Training.ipynb`
2. Aseg√∫rate de que el modelo se registre en MLflow Model Registry

### Error: "Puerto 5000 ya en uso"

**Soluci√≥n**: 
- Cierra el proceso que usa el puerto 5000
- O cambia el puerto en `settings.py` y reinicia MLflow

---

**‚úÖ Con estos cambios, la API puede iniciar sin MLflow y mostrar√° mensajes claros sobre qu√© hacer.**

