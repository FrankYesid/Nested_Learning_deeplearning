# Proyecto de PredicciÃ³n de Churn con Deep Learning y Nested Cross Validation

Sistema completo de Machine Learning para predicciÃ³n de churn de clientes usando Deep Learning, implementando Nested Cross Validation, arquitectura hexagonal, MLflow, API REST y frontend web.

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#descripciÃ³n)
- [Arquitectura](#arquitectura)
- [Dataset](#dataset)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Requisitos](#requisitos)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Uso](#uso)
- [MLflow](#mlflow)
- [API REST](#api-rest)
- [Frontend](#frontend)
- [Docker](#docker)
- [ContribuciÃ³n](#contribuciÃ³n)

## ğŸ¯ DescripciÃ³n

Este proyecto implementa un sistema end-to-end para predecir el churn (abandono) de clientes utilizando:

- **Deep Learning**: Redes neuronales con TensorFlow/Keras
- **Nested Cross Validation**: ValidaciÃ³n cruzada anidada para selecciÃ³n de hiperparÃ¡metros y evaluaciÃ³n robusta
- **Arquitectura Hexagonal**: SeparaciÃ³n clara entre dominio, aplicaciÃ³n e infraestructura
- **MLflow**: Tracking de experimentos, versionado de modelos y Model Registry
- **FastAPI**: API REST para servir predicciones
- **Frontend Web**: Interfaz de usuario para realizar predicciones
- **Docker**: ContenedorizaciÃ³n completa del sistema

## ğŸ—ï¸ Arquitectura

El proyecto sigue una **Arquitectura Hexagonal (Ports & Adapters)**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INFRASTRUCTURE                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  MLflow  â”‚  â”‚   API     â”‚  â”‚Frontend  â”‚  â”‚Persistenceâ”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   APPLICATION                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚  Use Cases   â”‚  â”‚     DTOs     â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DOMAIN                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚Entities  â”‚  â”‚  Models  â”‚  â”‚ Services â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Capas:

1. **Domain**: LÃ³gica de negocio pura, sin dependencias externas
   - Entidades: RepresentaciÃ³n de datos
   - Modelos: Modelos de ML
   - Servicios: LÃ³gica de preprocesamiento

2. **Application**: Casos de uso y orquestaciÃ³n
   - Use Cases: LÃ³gica de aplicaciÃ³n
   - DTOs: Objetos de transferencia de datos

3. **Infrastructure**: Implementaciones concretas
   - MLflow: Tracking y registro de modelos
   - API: FastAPI endpoints
   - Persistence: Repositorio de modelos
   - Web: Frontend HTML/CSS/JS

## ğŸ“Š Dataset

El dataset `churn_data.csv` contiene las siguientes columnas:

- `customerID`: Identificador Ãºnico del cliente
- `tenure`: Meses de permanencia
- `PhoneService`: Servicio telefÃ³nico (Yes/No)
- `Contract`: Tipo de contrato (Month-to-month/One year/Two year)
- `PaperlessBilling`: FacturaciÃ³n sin papel (Yes/No)
- `PaymentMethod`: MÃ©todo de pago
- `MonthlyCharges`: Cargos mensuales
- `TotalCharges`: Cargos totales
- `Churn`: Variable objetivo (Yes/No)

## ğŸ“ Estructura del Proyecto

```
project-churn-nested-learning/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ churn_data.csv              # Dataset
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA_Churn.ipynb         # AnÃ¡lisis exploratorio
â”‚   â””â”€â”€ 02_Nested_Learning_Training.ipynb  # Entrenamiento
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”‚   â””â”€â”€ churn_entity.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ deep_learning_model.py
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ preprocessing_service.py
â”‚   â”‚
â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â”œâ”€â”€ use_cases/
â”‚   â”‚   â”‚   â””â”€â”€ train_model_use_case.py
â”‚   â”‚   â””â”€â”€ dto/
â”‚   â”‚       â””â”€â”€ prediction_request.py
â”‚   â”‚
â”‚   â”œâ”€â”€ infrastructure/
â”‚   â”‚   â”œâ”€â”€ mlflow/
â”‚   â”‚   â”‚   â””â”€â”€ mlflow_tracking.py
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ persistence/
â”‚   â”‚   â”‚   â””â”€â”€ model_repository.py
â”‚   â”‚   â””â”€â”€ web/
â”‚   â”‚       â””â”€â”€ frontend/
â”‚   â”‚           â”œâ”€â”€ index.html
â”‚   â”‚           â”œâ”€â”€ styles.css
â”‚   â”‚           â””â”€â”€ app.js
â”‚   â”‚
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ settings.py
â”‚
â”œâ”€â”€ mlruns/                         # MLflow tracking (generado)
â”œâ”€â”€ models/                         # Modelos guardados (generado)
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .dockerignore
â””â”€â”€ README.md
```

## ğŸ”§ Requisitos

- Python 3.10+
- Docker y Docker Compose (opcional, para despliegue)
- MLflow Tracking Server

## ğŸ“¦ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone <repository-url>
cd Nested_Learning_deeplearning
```

### 2. Crear entorno virtual

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar MLflow (opcional)

Si quieres usar un servidor MLflow externo, configura la variable de entorno:

```bash
export MLFLOW_TRACKING_URI=http://localhost:5000
```

## ğŸš€ Uso

### 1. AnÃ¡lisis Exploratorio de Datos

```bash
jupyter notebook notebooks/01_EDA_Churn.ipynb
```

Ejecuta todas las celdas para realizar el anÃ¡lisis exploratorio.

### 2. Entrenamiento del Modelo

```bash
jupyter notebook notebooks/02_Nested_Learning_Training.ipynb
```

Este notebook:
- Carga y preprocesa los datos
- Realiza Nested Cross Validation
- Entrena mÃºltiples modelos con diferentes hiperparÃ¡metros
- Registra todo en MLflow
- Guarda el mejor modelo en MLflow Model Registry

**Nota**: El entrenamiento puede tardar varios minutos dependiendo de tu hardware.

### 3. Iniciar MLflow Tracking Server

```bash
mlflow server --host 0.0.0.0 --port 5000 --default-artifact-root ./mlruns
```

Accede a la UI en: http://localhost:5000

### 4. Iniciar la API

```bash
cd src/infrastructure/api
python -m uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

O desde la raÃ­z:

```bash
python -m uvicorn src.infrastructure.api.main:app --host 0.0.0.0 --port 8000
```

La API estarÃ¡ disponible en: http://localhost:8000

### 5. Acceder al Frontend

Abre en tu navegador:
- http://localhost:8000/frontend
- O directamente: http://localhost:8000/static/index.html

## ğŸ“ˆ MLflow

### Acceder a MLflow UI

```bash
mlflow ui --backend-store-uri ./mlruns
```

Luego abre: http://localhost:5000

### Ver Modelos Registrados

1. Ve a la pestaÃ±a "Models" en MLflow UI
2. Busca el modelo: `churn_deep_learning_model`
3. VerÃ¡s todas las versiones y sus stages

### Cargar Modelo desde MLflow

El cÃ³digo de la API carga automÃ¡ticamente el modelo desde MLflow Model Registry.

## ğŸ”Œ API REST

### Endpoints

#### `GET /`
InformaciÃ³n general de la API.

#### `GET /health`
Health check del servicio.

#### `GET /model/info`
InformaciÃ³n del modelo actual cargado.

#### `POST /predict`
Realiza una predicciÃ³n de churn.

**Request Body:**
```json
{
  "tenure": 12,
  "phone_service": "Yes",
  "contract": "Month-to-month",
  "paperless_billing": "Yes",
  "payment_method": "Electronic check",
  "monthly_charges": 70.5,
  "total_charges": 846.0,
  "customer_id": "1234-ABCDE"
}
```

**Response:**
```json
{
  "churn_probability": 0.75,
  "churn_prediction": "Yes",
  "customer_id": "1234-ABCDE"
}
```

### DocumentaciÃ³n Interactiva

FastAPI proporciona documentaciÃ³n automÃ¡tica:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ¨ Frontend

El frontend es una aplicaciÃ³n web simple que permite:
- Ingresar datos del cliente
- Realizar predicciones en tiempo real
- Visualizar probabilidades de churn
- Ver resultados con feedback visual

Accede en: http://localhost:8000/frontend

## ğŸ³ Docker

### Construir y ejecutar con Docker Compose

```bash
cd docker
docker-compose up --build
```

Esto iniciarÃ¡:
- **MLflow Tracking Server** en http://localhost:5000
- **API FastAPI** en http://localhost:8000

### Comandos Ãºtiles

```bash
# Construir imÃ¡genes
docker-compose build

# Iniciar servicios
docker-compose up

# Iniciar en segundo plano
docker-compose up -d

# Ver logs
docker-compose logs -f

# Detener servicios
docker-compose down

# Detener y eliminar volÃºmenes
docker-compose down -v
```

### Construir imagen manualmente

```bash
docker build -f docker/Dockerfile -t churn-api:latest .
docker run -p 8000:8000 -e MLFLOW_TRACKING_URI=http://localhost:5000 churn-api:latest
```

## ğŸ”¬ Nested Cross Validation

El proyecto implementa **Nested Cross Validation** para:

1. **Outer CV (K=5)**: EvalÃºa el rendimiento final del modelo
2. **Inner CV (K=3)**: Selecciona los mejores hiperparÃ¡metros

Esto evita el sobreajuste y proporciona una evaluaciÃ³n mÃ¡s robusta del modelo.

## ğŸ“ Notas Importantes

1. **Preprocessing Service**: Debe ser entrenado antes de usar la API. Se guarda durante el entrenamiento.

2. **MLflow**: AsegÃºrate de que el servidor MLflow estÃ© corriendo antes de iniciar la API.

3. **Modelo**: El modelo debe estar registrado en MLflow Model Registry con stage "Production".

4. **Datos**: El dataset debe estar en `data/churn_data.csv`.

## ğŸ¤ ContribuciÃ³n

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT.

## ğŸ‘¥ Autores

Equipo Senior:
- Arquitecto de Software
- Ingeniero de Machine Learning
- Ingeniero MLOps
- Desarrollador Backend
- Desarrollador Frontend

## ğŸ™ Agradecimientos

- TensorFlow/Keras por el framework de Deep Learning
- MLflow por el tracking de experimentos
- FastAPI por el framework web moderno
- La comunidad de cÃ³digo abierto

---

**Â¡Listo para producciÃ³n!** ğŸš€

