# Proyecto de Predicci√≥n de Churn con Deep Learning y Nested Cross Validation

Sistema completo de Machine Learning para predicci√≥n de churn de clientes usando Deep Learning, implementando Nested Cross Validation, arquitectura hexagonal, MLflow, API REST y frontend web.

## üìã Tabla de Contenidos

- [Descripci√≥n](#descripci√≥n)
- [Arquitectura](#arquitectura)
- [Dataset](#dataset)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Requisitos](#requisitos)
- [Instalaci√≥n](#instalaci√≥n)
- [Uso](#uso)
- [MLflow](#mlflow)
- [API REST](#api-rest)
- [Frontend](#frontend)
- [Docker](#docker)
- [Contribuci√≥n](#contribuci√≥n)

## üéØ Descripci√≥n

Este proyecto implementa un sistema end-to-end para predecir el churn (abandono) de clientes utilizando:

- **Deep Learning**: Redes neuronales con TensorFlow/Keras
- **Nested Cross Validation**: Validaci√≥n cruzada anidada para selecci√≥n de hiperpar√°metros y evaluaci√≥n robusta
- **Arquitectura Hexagonal**: Separaci√≥n clara entre dominio, aplicaci√≥n e infraestructura
- **MLflow**: Tracking de experimentos, versionado de modelos y Model Registry
- **FastAPI**: API REST para servir predicciones
- **Frontend Web**: Interfaz de usuario para realizar predicciones
- **Docker**: Contenedorizaci√≥n completa del sistema

## üèóÔ∏è Arquitectura

El proyecto sigue una **Arquitectura Hexagonal (Ports & Adapters)**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    INFRASTRUCTURE                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  MLflow  ‚îÇ  ‚îÇ   API     ‚îÇ  ‚îÇFrontend  ‚îÇ  ‚îÇPersistence‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üï
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   APPLICATION                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
‚îÇ  ‚îÇ  Use Cases   ‚îÇ  ‚îÇ     DTOs     ‚îÇ                    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üï
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      DOMAIN                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇEntities  ‚îÇ  ‚îÇ  Models  ‚îÇ  ‚îÇ Services ‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Capas:

1. **Domain**: L√≥gica de negocio pura, sin dependencias externas
   - Entidades: Representaci√≥n de datos
   - Modelos: Modelos de ML
   - Servicios: L√≥gica de preprocesamiento

2. **Application**: Casos de uso y orquestaci√≥n
   - Use Cases: L√≥gica de aplicaci√≥n
   - DTOs: Objetos de transferencia de datos

3. **Infrastructure**: Implementaciones concretas
   - MLflow: Tracking y registro de modelos
   - API: FastAPI endpoints
   - Persistence: Repositorio de modelos
   - Web: Frontend HTML/CSS/JS

## üìä Dataset

El dataset `churn_data.csv` contiene las siguientes columnas:

- `customerID`: Identificador √∫nico del cliente
- `tenure`: Meses de permanencia
- `PhoneService`: Servicio telef√≥nico (Yes/No)
- `Contract`: Tipo de contrato (Month-to-month/One year/Two year)
- `PaperlessBilling`: Facturaci√≥n sin papel (Yes/No)
- `PaymentMethod`: M√©todo de pago
- `MonthlyCharges`: Cargos mensuales
- `TotalCharges`: Cargos totales
- `Churn`: Variable objetivo (Yes/No)

## üìÅ Estructura del Proyecto

```
project-churn-nested-learning/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ churn_data.csv              # Dataset
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_EDA_Churn.ipynb         # An√°lisis exploratorio
‚îÇ   ‚îî‚îÄ‚îÄ 02_Nested_Learning_Training.ipynb  # Entrenamiento
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ domain/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entities/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ churn_entity.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ deep_learning_model.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ preprocessing_service.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ application/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ use_cases/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_model_use_case.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dto/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ prediction_request.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mlflow/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mlflow_tracking.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ persistence/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_repository.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ web/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ frontend/
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ styles.css
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ app.js
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îî‚îÄ‚îÄ settings.py
‚îÇ
‚îú‚îÄ‚îÄ mlruns/                         # MLflow tracking (generado)
‚îú‚îÄ‚îÄ models/                         # Modelos guardados (generado)
‚îÇ
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .dockerignore
‚îî‚îÄ‚îÄ README.md
```

## üîß Requisitos

- **Python 3.10 o 3.11** (‚ö†Ô∏è NO compatible con Python 3.12+ debido a TensorFlow 2.15.0)
- Docker y Docker Compose (opcional, para despliegue)
- MLflow Tracking Server

> üìå **IMPORTANTE**: TensorFlow 2.15.0 solo soporta Python 3.9, 3.10 y 3.11.  
> Ver [VERSION_PYTHON.md](VERSION_PYTHON.md) para m√°s detalles sobre compatibilidad.

## üì¶ Instalaci√≥n

### 1. Clonar el repositorio

```bash
git clone <repository-url>
cd Nested_Learning_deeplearning
```

### 2. Verificar versi√≥n de Python

```bash
# Verificar que tienes Python 3.10 o 3.11
python --version

# Si tienes Python 3.12+, necesitas instalar Python 3.10 o 3.11
# Descarga desde: https://www.python.org/downloads/
```

### 3. Crear entorno virtual

**Con UV (Recomendado):**
```bash
# Crear entorno con Python 3.10
uv venv --python 3.10

# O con Python 3.11
uv venv --python 3.11

# Activar entorno (Windows PowerShell)
.venv\Scripts\Activate.ps1

# Activar entorno (macOS/Linux)
source .venv/bin/activate
```

**M√©todo tradicional:**
```bash
# Aseg√∫rate de usar Python 3.10 o 3.11
python3.10 -m venv venv  # o python3.11
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 4. Instalar dependencias

```bash
# Con UV
uv pip install -r requirements.txt

# O con pip tradicional
pip install -r requirements.txt
```

### 5. Configurar MLflow (opcional)

Si quieres usar un servidor MLflow externo, configura la variable de entorno:

```bash
export MLFLOW_TRACKING_URI=http://localhost:5000
```

## üöÄ Uso

### 1. An√°lisis Exploratorio de Datos

```bash
jupyter notebook notebooks/01_EDA_Churn.ipynb
```

Ejecuta todas las celdas para realizar el an√°lisis exploratorio.

### 2. Entrenamiento del Modelo

```bash
jupyter notebook notebooks/02_Nested_Learning_Training.ipynb
```

Este notebook:
- Carga y preprocesa los datos
- Realiza Nested Cross Validation
- Entrena m√∫ltiples modelos con diferentes hiperpar√°metros
- Registra todo en MLflow
- Guarda el mejor modelo en MLflow Model Registry

**Nota**: El entrenamiento puede tardar varios minutos dependiendo de tu hardware.

### 3. Iniciar MLflow Tracking Server

```bash
mlflow server --host 0.0.0.0 --port 5000 --default-artifact-root ./mlruns
```

Accede a la UI en: http://localhost:5000

### 4. Iniciar la API

```bash
cd src/infrastructure/api
python -m uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

O desde la ra√≠z:

```bash
python -m uvicorn src.infrastructure.api.main:app --host 0.0.0.0 --port 8000
```

La API estar√° disponible en: http://localhost:8000

### 5. Acceder al Frontend

Abre en tu navegador:
- http://localhost:8000/frontend
- O directamente: http://localhost:8000/static/index.html

## üìà MLflow

### Acceder a MLflow UI

```bash
mlflow ui --backend-store-uri ./mlruns
```

Luego abre: http://localhost:5000

### Ver Modelos Registrados

1. Ve a la pesta√±a "Models" en MLflow UI
2. Busca el modelo: `churn_deep_learning_model`
3. Ver√°s todas las versiones y sus stages

### Cargar Modelo desde MLflow

El c√≥digo de la API carga autom√°ticamente el modelo desde MLflow Model Registry.

## üîå API REST

### Endpoints

#### `GET /`
Informaci√≥n general de la API.

#### `GET /health`
Health check del servicio.

#### `GET /model/info`
Informaci√≥n del modelo actual cargado.

#### `POST /predict`
Realiza una predicci√≥n de churn.

**Request Body:**
```json
{
  "tenure": 12,
  "phone_service": "Yes",
  "contract": "Month-to-month",
  "paperless_billing": "Yes",
  "payment_method": "Electronic check",
  "monthly_charges": 70.5,
  "total_charges": 846.0,
  "customer_id": "1234-ABCDE"
}
```

**Response:**
```json
{
  "churn_probability": 0.75,
  "churn_prediction": "Yes",
  "customer_id": "1234-ABCDE"
}
```

### Documentaci√≥n Interactiva

FastAPI proporciona documentaci√≥n autom√°tica:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## üé® Frontend

El frontend es una aplicaci√≥n web simple que permite:
- Ingresar datos del cliente
- Realizar predicciones en tiempo real
- Visualizar probabilidades de churn
- Ver resultados con feedback visual

Accede en: http://localhost:8000/frontend

## üê≥ Docker

### Construir y ejecutar con Docker Compose

```bash
cd docker
docker-compose up --build
```

Esto iniciar√°:
- **MLflow Tracking Server** en http://localhost:5000
- **API FastAPI** en http://localhost:8000

### Comandos √∫tiles

```bash
# Construir im√°genes
docker-compose build

# Iniciar servicios
docker-compose up

# Iniciar en segundo plano
docker-compose up -d

# Ver logs
docker-compose logs -f

# Detener servicios
docker-compose down

# Detener y eliminar vol√∫menes
docker-compose down -v
```

### Construir imagen manualmente

```bash
docker build -f docker/Dockerfile -t churn-api:latest .
docker run -p 8000:8000 -e MLFLOW_TRACKING_URI=http://localhost:5000 churn-api:latest
```

## üî¨ Nested Cross Validation

El proyecto implementa **Nested Cross Validation** para:

1. **Outer CV (K=5)**: Eval√∫a el rendimiento final del modelo
2. **Inner CV (K=3)**: Selecciona los mejores hiperpar√°metros

Esto evita el sobreajuste y proporciona una evaluaci√≥n m√°s robusta del modelo.

## üìù Notas Importantes

1. **Preprocessing Service**: Debe ser entrenado antes de usar la API. Se guarda durante el entrenamiento.

2. **MLflow**: Aseg√∫rate de que el servidor MLflow est√© corriendo antes de iniciar la API.

3. **Modelo**: El modelo debe estar registrado en MLflow Model Registry con stage "Production".

4. **Datos**: El dataset debe estar en `data/churn_data.csv`.

## ü§ù Contribuci√≥n

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT.

## üë• Autores

Equipo Senior:
- Arquitecto de Software
- Ingeniero de Machine Learning
- Ingeniero MLOps
- Desarrollador Backend
- Desarrollador Frontend

## üôè Agradecimientos

- TensorFlow/Keras por el framework de Deep Learning
- MLflow por el tracking de experimentos
- FastAPI por el framework web moderno
- La comunidad de c√≥digo abierto

---

**¬°Listo para producci√≥n!** üöÄ

