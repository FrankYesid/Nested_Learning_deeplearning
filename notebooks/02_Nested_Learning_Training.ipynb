{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Entrenamiento de Modelo Deep Learning con Nested Cross Validation\n",
        "\n",
        "Este notebook implementa el entrenamiento de un modelo de Deep Learning para predicci√≥n de churn usando Nested Cross Validation y registra todo en MLflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Directorio del proyecto agregado al PATH: d:\\GitHub\\Nested_Learning_deeplearning\n",
            "‚úì Librer√≠as importadas correctamente\n",
            "‚úì MLflow Tracking URI: http://localhost:5000\n",
            "‚úì MLflow Experiment: churn_prediction_nested_cv\n"
          ]
        }
      ],
      "source": [
        "# Importar librer√≠as necesarias\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Agregar el directorio ra√≠z del proyecto al PATH\n",
        "# El notebook est√° en notebooks/, necesitamos agregar el directorio padre (ra√≠z del proyecto)\n",
        "current_dir = Path.cwd()\n",
        "if current_dir.name == 'notebooks':\n",
        "    # Estamos en la carpeta notebooks, agregar el directorio padre\n",
        "    project_root = current_dir.parent\n",
        "else:\n",
        "    # Estamos en la ra√≠z, usar el directorio actual\n",
        "    project_root = current_dir\n",
        "\n",
        "# Agregar al PATH si no est√° ya\n",
        "project_root_str = str(project_root)\n",
        "if project_root_str not in sys.path:\n",
        "    sys.path.insert(0, project_root_str)\n",
        "\n",
        "print(f\"‚úì Directorio del proyecto agregado al PATH: {project_root}\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mlflow\n",
        "\n",
        "# Ahora podemos importar desde src\n",
        "from src.domain.services.preprocessing_service import PreprocessingService\n",
        "from src.domain.models.deep_learning_model import DeepLearningModel\n",
        "from src.application.use_cases.train_model_use_case import TrainModelUseCase\n",
        "from src.infrastructure.mlflow.mlflow_tracking import MLflowTracking\n",
        "from src.config.settings import settings\n",
        "\n",
        "print(\"‚úì Librer√≠as importadas correctamente\")\n",
        "print(f\"‚úì MLflow Tracking URI: {settings.MLFLOW_TRACKING_URI}\")\n",
        "print(f\"‚úì MLflow Experiment: {settings.MLFLOW_EXPERIMENT_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Carga y Preparaci√≥n de Datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones del dataset: (7042, 9)\n",
            "\n",
            "Primeras filas:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.50</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7795-CFOCW</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   customerID  tenure PhoneService        Contract PaperlessBilling  \\\n",
              "0  7590-VHVEG       1           No  Month-to-month              Yes   \n",
              "1  5575-GNVDE      34          Yes        One year               No   \n",
              "2  3668-QPYBK       2          Yes  Month-to-month              Yes   \n",
              "3  7795-CFOCW      45           No        One year               No   \n",
              "4  9237-HQITU       2          Yes  Month-to-month              Yes   \n",
              "\n",
              "               PaymentMethod  MonthlyCharges  TotalCharges Churn  \n",
              "0           Electronic check           29.85         29.85    No  \n",
              "1               Mailed check           56.95       1889.50    No  \n",
              "2               Mailed check           53.85        108.15   Yes  \n",
              "3  Bank transfer (automatic)           42.30       1840.75    No  \n",
              "4           Electronic check           70.70        151.65   Yes  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cargar dataset\n",
        "df = pd.read_csv('../data/churn_data_clean.csv')\n",
        "\n",
        "print(f\"Dimensiones del dataset: {df.shape}\")\n",
        "print(f\"\\nPrimeras filas:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones de X: (7042, 7)\n",
            "Dimensiones de y: (7042,)\n",
            "\n",
            "Distribuci√≥n de clases:\n",
            "  Clase 0: 5173 (73.46%)\n",
            "  Clase 1: 1869 (26.54%)\n"
          ]
        }
      ],
      "source": [
        "# Inicializar servicios\n",
        "preprocessing_service = PreprocessingService()\n",
        "\n",
        "# Preprocesar datos\n",
        "X, y = preprocessing_service.preprocess_pipeline(df, fit=True)\n",
        "\n",
        "print(f\"Dimensiones de X: {X.shape}\")\n",
        "print(f\"Dimensiones de y: {y.shape}\")\n",
        "print(f\"\\nDistribuci√≥n de clases:\")\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f\"  Clase {u}: {c} ({c/len(y)*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuraci√≥n de MLflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/02 02:25:10 INFO mlflow.tracking.fluent: Experiment with name 'churn_prediction_nested_cv' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experimento configurado: churn_prediction_nested_cv\n",
            "Tracking URI: http://localhost:5000\n"
          ]
        }
      ],
      "source": [
        "# Configurar MLflow\n",
        "settings.ensure_directories()\n",
        "\n",
        "mlflow.set_tracking_uri(settings.MLFLOW_TRACKING_URI)\n",
        "mlflow.set_experiment(settings.MLFLOW_EXPERIMENT_NAME)\n",
        "\n",
        "mlflow_tracking = MLflowTracking()\n",
        "\n",
        "print(f\"Experimento configurado: {settings.MLFLOW_EXPERIMENT_NAME}\")\n",
        "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Definici√≥n de Hiperpar√°metros para B√∫squeda\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de combinaciones de hiperpar√°metros: 4\n",
            "\n",
            "Configuraci√≥n 1:\n",
            "  hidden_layers: 2\n",
            "  units_per_layer: [64, 32]\n",
            "  dropout_rate: 0.2\n",
            "  learning_rate: 0.001\n",
            "  batch_size: 32\n",
            "  epochs: 50\n",
            "  activation: relu\n",
            "  optimizer: adam\n",
            "\n",
            "Configuraci√≥n 2:\n",
            "  hidden_layers: 2\n",
            "  units_per_layer: [128, 64]\n",
            "  dropout_rate: 0.3\n",
            "  learning_rate: 0.001\n",
            "  batch_size: 32\n",
            "  epochs: 50\n",
            "  activation: relu\n",
            "  optimizer: adam\n",
            "\n",
            "Configuraci√≥n 3:\n",
            "  hidden_layers: 3\n",
            "  units_per_layer: [128, 64, 32]\n",
            "  dropout_rate: 0.3\n",
            "  learning_rate: 0.0005\n",
            "  batch_size: 64\n",
            "  epochs: 50\n",
            "  activation: relu\n",
            "  optimizer: adam\n",
            "\n",
            "Configuraci√≥n 4:\n",
            "  hidden_layers: 2\n",
            "  units_per_layer: [256, 128]\n",
            "  dropout_rate: 0.4\n",
            "  learning_rate: 0.0005\n",
            "  batch_size: 64\n",
            "  epochs: 50\n",
            "  activation: relu\n",
            "  optimizer: adam\n"
          ]
        }
      ],
      "source": [
        "# Definir grilla de hiperpar√°metros para b√∫squeda\n",
        "hyperparameter_grid = [\n",
        "    {\n",
        "        'hidden_layers': 2,\n",
        "        'units_per_layer': [64, 32],\n",
        "        'dropout_rate': 0.2,\n",
        "        'learning_rate': 0.001,\n",
        "        'batch_size': 32,\n",
        "        'epochs': 50,\n",
        "        'activation': 'relu',\n",
        "        'optimizer': 'adam'\n",
        "    },\n",
        "    {\n",
        "        'hidden_layers': 2,\n",
        "        'units_per_layer': [128, 64],\n",
        "        'dropout_rate': 0.3,\n",
        "        'learning_rate': 0.001,\n",
        "        'batch_size': 32,\n",
        "        'epochs': 50,\n",
        "        'activation': 'relu',\n",
        "        'optimizer': 'adam'\n",
        "    },\n",
        "    {\n",
        "        'hidden_layers': 3,\n",
        "        'units_per_layer': [128, 64, 32],\n",
        "        'dropout_rate': 0.3,\n",
        "        'learning_rate': 0.0005,\n",
        "        'batch_size': 64,\n",
        "        'epochs': 50,\n",
        "        'activation': 'relu',\n",
        "        'optimizer': 'adam'\n",
        "    },\n",
        "    {\n",
        "        'hidden_layers': 2,\n",
        "        'units_per_layer': [256, 128],\n",
        "        'dropout_rate': 0.4,\n",
        "        'learning_rate': 0.0005,\n",
        "        'batch_size': 64,\n",
        "        'epochs': 50,\n",
        "        'activation': 'relu',\n",
        "        'optimizer': 'adam'\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"Total de combinaciones de hiperpar√°metros: {len(hyperparameter_grid)}\")\n",
        "for i, hp in enumerate(hyperparameter_grid):\n",
        "    print(f\"\\nConfiguraci√≥n {i+1}:\")\n",
        "    for key, value in hp.items():\n",
        "        print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Entrenamiento con Nested Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuraci√≥n de Nested Cross Validation:\n",
            "  - Folds externos (evaluaci√≥n final): 5\n",
            "  - Folds internos (selecci√≥n de hiperpar√°metros): 3\n",
            "\n",
            "Iniciando entrenamiento...\n"
          ]
        }
      ],
      "source": [
        "# Inicializar caso de uso\n",
        "train_use_case = TrainModelUseCase(preprocessing_service)\n",
        "\n",
        "# Configurar Nested CV\n",
        "outer_k = 5  # Folds externos\n",
        "inner_k = 3  # Folds internos para selecci√≥n de hiperpar√°metros\n",
        "\n",
        "print(f\"Configuraci√≥n de Nested Cross Validation:\")\n",
        "print(f\"  - Folds externos (evaluaci√≥n final): {outer_k}\")\n",
        "print(f\"  - Folds internos (selecci√≥n de hiperpar√°metros): {inner_k}\")\n",
        "print(f\"\\nIniciando entrenamiento...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando Nested Cross Validation: 5 folds externos, 3 folds internos\n",
            "\n",
            "============================================================\n",
            "Fold Externo 1/5\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# Configuraci√≥n de warnings y logs\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "# TensorFlow: solo errores cr√≠ticos\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # 0=ALL, 1=INFO, 2=WARNING, 3=ERROR\n",
        "\n",
        "# Python warnings\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=DeprecationWarning\n",
        ")\n",
        "\n",
        "# Logging de TensorFlow\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "# Iniciar run principal en MLflow\n",
        "with mlflow.start_run(run_name=\"nested_cv_training\") as parent_run:\n",
        "    # Registrar par√°metros generales\n",
        "    mlflow.log_params({\n",
        "        \"outer_cv_folds\": outer_k,\n",
        "        \"inner_cv_folds\": inner_k,\n",
        "        \"dataset_size\": len(df),\n",
        "        \"features_count\": X.shape[1],\n",
        "        \"hyperparameter_combinations\": len(hyperparameter_grid)\n",
        "    })\n",
        "    \n",
        "    # Ejecutar Nested Cross Validation\n",
        "    results = train_use_case.nested_cross_validation(\n",
        "        df=df,\n",
        "        outer_k=outer_k,\n",
        "        inner_k=inner_k,\n",
        "        hyperparameter_grid=hyperparameter_grid,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    # Registrar m√©tricas promedio\n",
        "    mlflow.log_metrics(results['average_metrics'])\n",
        "    \n",
        "    # Registrar mejores hiperpar√°metros\n",
        "    mlflow.log_params({\n",
        "        f\"best_{k}\": v for k, v in results['best_hyperparameters'].items()\n",
        "    })\n",
        "    \n",
        "    # Guardar y registrar el mejor modelo\n",
        "    if results['best_model'] is not None:\n",
        "        # Guardar modelo temporalmente\n",
        "        model_path = \"../models/best_churn_model\"\n",
        "        results['best_model'].save_model(model_path)\n",
        "        \n",
        "        # Registrar modelo en MLflow\n",
        "        mlflow.keras.log_model(\n",
        "            results['best_model'].model,\n",
        "            artifact_path=\"model\",\n",
        "            registered_model_name=settings.MODEL_NAME\n",
        "        )\n",
        "        \n",
        "        # Registrar en Model Registry con stage Production\n",
        "        model_uri = f\"runs:/{mlflow.active_run().info.run_id}/model\"\n",
        "        mlflow_tracking.register_model_version(\n",
        "            model_uri=model_uri,\n",
        "            registered_model_name=settings.MODEL_NAME,\n",
        "            stage=\"Production\"\n",
        "        )\n",
        "        \n",
        "        print(f\"\\n‚úÖ Modelo registrado en MLflow Model Registry:\")\n",
        "        print(f\"   Nombre: {settings.MODEL_NAME}\")\n",
        "        print(f\"   Stage: Production\")\n",
        "        print(f\"   URI: {model_uri}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Entrenamiento completado exitosamente\")\n",
        "    print(f\"Resultados de la Nested CV:\")\n",
        "    print(f\"  M√©tricas promedio: {results['average_metrics']}\")\n",
        "    print(f\"  Mejores hiperpar√°metros: {results['best_hyperparameters']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Resultados del Entrenamiento\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mostrar resultados detallados\n",
        "print(\"=\"*60)\n",
        "print(\"RESUMEN DE RESULTADOS - NESTED CROSS VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüìä M√âTRICAS PROMEDIO (en todos los folds externos):\")\n",
        "for metric, value in results['average_metrics'].items():\n",
        "    print(f\"   {metric}: {value:.4f}\")\n",
        "\n",
        "print(\"\\nüîß MEJORES HIPERPAR√ÅMETROS:\")\n",
        "for key, value in results['best_hyperparameters'].items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "print(\"\\nüìà RESULTADOS POR FOLD EXTERNO:\")\n",
        "for fold_result in results['nested_cv_results']:\n",
        "    print(f\"\\n   Fold {fold_result['fold']}:\")\n",
        "    for metric, value in fold_result['test_metrics'].items():\n",
        "        print(f\"      {metric}: {value:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizar resultados por fold\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fold_numbers = [r['fold'] for r in results['nested_cv_results']]\n",
        "f1_scores = [r['test_metrics']['f1_score'] for r in results['nested_cv_results']]\n",
        "accuracies = [r['test_metrics']['accuracy'] for r in results['nested_cv_results']]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].plot(fold_numbers, f1_scores, marker='o', linewidth=2, markersize=8, label='F1-Score')\n",
        "axes[0].axhline(y=results['average_metrics']['f1_score'], color='r', linestyle='--', label='Promedio')\n",
        "axes[0].set_title('F1-Score por Fold Externo', fontweight='bold')\n",
        "axes[0].set_xlabel('Fold')\n",
        "axes[0].set_ylabel('F1-Score')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(fold_numbers, accuracies, marker='o', linewidth=2, markersize=8, label='Accuracy', color='green')\n",
        "axes[1].axhline(y=results['average_metrics']['accuracy'], color='r', linestyle='--', label='Promedio')\n",
        "axes[1].set_title('Accuracy por Fold Externo', fontweight='bold')\n",
        "axes[1].set_xlabel('Fold')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Guardar Preprocessing Service\n",
        "\n",
        "Es importante guardar el preprocessing service para poder usarlo en producci√≥n.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar preprocessing service usando pickle\n",
        "import pickle\n",
        "import joblib\n",
        "\n",
        "preprocessing_path = \"../models/preprocessing_service.pkl\"\n",
        "joblib.dump(preprocessing_service, preprocessing_path)\n",
        "\n",
        "print(f\"‚úÖ Preprocessing service guardado en: {preprocessing_path}\")\n",
        "\n",
        "# Tambi√©n registrar como artefacto en MLflow\n",
        "mlflow.log_artifact(preprocessing_path, \"preprocessing\")\n",
        "print(\"‚úÖ Preprocessing service registrado en MLflow\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Verificaci√≥n del Modelo en MLflow\n",
        "\n",
        "Verificar que el modelo se haya registrado correctamente en MLflow Model Registry.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar modelo en MLflow\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "client = MlflowClient(settings.MLFLOW_TRACKING_URI)\n",
        "\n",
        "try:\n",
        "    latest_version = client.get_latest_versions(settings.MODEL_NAME, stages=[\"Production\"])[0]\n",
        "    print(f\"‚úÖ Modelo encontrado en Model Registry:\")\n",
        "    print(f\"   Nombre: {latest_version.name}\")\n",
        "    print(f\"   Versi√≥n: {latest_version.version}\")\n",
        "    print(f\"   Stage: {latest_version.current_stage}\")\n",
        "    print(f\"   Run ID: {latest_version.run_id}\")\n",
        "    \n",
        "    # Obtener informaci√≥n del run\n",
        "    run = client.get_run(latest_version.run_id)\n",
        "    print(f\"\\nüìä M√©tricas del modelo:\")\n",
        "    for key, value in run.data.metrics.items():\n",
        "        print(f\"   {key}: {value:.4f}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error al verificar modelo: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Conclusi√≥n\n",
        "\n",
        "El modelo ha sido entrenado exitosamente usando Nested Cross Validation y registrado en MLflow. \n",
        "\n",
        "**Pr√≥ximos pasos:**\n",
        "1. El modelo est√° disponible en MLflow Model Registry\n",
        "2. La API puede cargar el modelo desde MLflow\n",
        "3. El frontend puede consumir la API para realizar predicciones\n",
        "\n",
        "**Para usar el modelo:**\n",
        "- Accede a MLflow UI: `http://localhost:5000`\n",
        "- El modelo est√° registrado como: `churn_deep_learning_model`\n",
        "- Stage: `Production`\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
